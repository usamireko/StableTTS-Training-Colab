{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usamireko/StableTTS-Training-Colab/blob/main/StableTTS_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIlQplvca68K",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Installation\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "!git clone https://github.com/KdaiP/StableTTS.git\n",
        "%cd /content/StableTTS\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrLkZUMIc-Cz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown A pretrained model will be downloaded in the folder checkpoints created for you inside the StableTTS folder on you GDrive :)\n",
        "project_name = \"\" #@param {type:\"string\"}\n",
        "!mkdir /content/drive/MyDrive/StableTTS/{project_name}\n",
        "!mkdir /content/drive/MyDrive/StableTTS/{project_name}/checkpoints\n",
        "!mkdir /content/drive/MyDrive/StableTTS/{project_name}/wavs\n",
        "!mkdir /content/drive/MyDrive/StableTTS/{project_name}/logs\n",
        "!wget \"https://huggingface.co/KdaiP/StableTTS1.1/resolve/main/StableTTS/checkpoint_0.pt\" -O /content/drive/MyDrive/StableTTS/{project_name}/checkpoints/checkpoint_0.pt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Convert your Tacotron2 list to StableTTS\n",
        "def update_transcript(file_path, project_name):\n",
        "    # Read the list.txt file\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Update each line with the new path format\n",
        "    updated_lines = []\n",
        "    for line in lines:\n",
        "        parts = line.split('|')\n",
        "        wav_file = parts[0].replace('wavs/', f'/content/drive/MyDrive/StableTTS/{project_name}/wavs/')\n",
        "        text = parts[1].strip()  # Strip to remove any extra whitespace/newlines\n",
        "        updated_lines.append(f'{wav_file}|{text}\\n')\n",
        "\n",
        "    # Write the updated lines back to the file (or a new file if preferred)\n",
        "    with open(file_path, 'w', encoding='utf-8') as file:\n",
        "        file.writelines(updated_lines)\n",
        "\n",
        "    print(f\"File '{file_path}' updated successfully.\")\n",
        "\n",
        "\n",
        "# Specify the path to your list.txt in Google Drive\n",
        "file_path = '' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "# Run the update function\n",
        "update_transcript(file_path, project_name)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EBMuKAqUO_Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Download the FireFly-GAN vocoder\n",
        "!wget \"https://github.com/fishaudio/vocoder/releases/download/1.0.0/firefly-gan-base-generator.ckpt\" -O /content/StableTTS/vocoders/pretrained/firefly-gan-base-generator.ckpt"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GghVEvC2XcEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now upload your wav files into the wavs folder created inside the StableTTS/{project_name} folder\n",
        "\n",
        "Your list should have been adapted to point the full path of the wav instead of just \"wavs/xxx.wav\" as in Tacotron2\n",
        "\n",
        "output_filelist_path points to a JSON file created in the same place as where your list.txt is located,"
      ],
      "metadata": {
        "id": "WYoKgqArsx4u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6dfYzOwP5Nd"
      },
      "source": [
        "**Configuration**\n",
        "\n",
        "_resample is not really needed_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/StableTTS/preprocess.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from dataclasses import dataclass, asdict\n",
        "\n",
        "import torch\n",
        "from torch.multiprocessing import Pool, set_start_method\n",
        "import torchaudio\n",
        "\n",
        "from config import MelConfig, TrainConfig\n",
        "from utils.audio import LogMelSpectrogram, load_and_resample_audio\n",
        "\n",
        "from text.mandarin import chinese_to_cnm3\n",
        "from text.english import english_to_ipa2\n",
        "from text.japanese import japanese_to_ipa2\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "@dataclass\n",
        "class DataConfig:\n",
        "    input_filelist_path = '' #@param {type:\"string\"}\n",
        "    output_filelist_path = '' #@param {type:\"string\"}\n",
        "    output_feature_path = '' #@param {type:\"string\"}\n",
        "    language = 'english' #@param [\"english\", \"japanese\", \"chinese\"]\n",
        "    resample = False #@param{type:\"boolean\"}\n",
        "\n",
        "g2p_mapping = {\n",
        "    'chinese': chinese_to_cnm3,\n",
        "    'japanese': japanese_to_ipa2,\n",
        "    'english': english_to_ipa2,\n",
        "}\n",
        "\n",
        "data_config = DataConfig()\n",
        "train_config = TrainConfig()\n",
        "mel_config = MelConfig()\n",
        "\n",
        "input_filelist_path = data_config.input_filelist_path\n",
        "output_filelist_path = data_config.output_filelist_path\n",
        "output_feature_path = data_config.output_feature_path\n",
        "\n",
        "# Ensure output directories exist\n",
        "output_mel_dir = os.path.join(output_feature_path, 'mels')\n",
        "os.makedirs(output_mel_dir, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(output_filelist_path), exist_ok=True)\n",
        "\n",
        "if data_config.resample:\n",
        "    output_wav_dir = os.path.join(output_feature_path, 'waves')\n",
        "    os.makedirs(output_wav_dir, exist_ok=True)\n",
        "\n",
        "mel_extractor = LogMelSpectrogram(**asdict(mel_config)).to(device)\n",
        "\n",
        "g2p = g2p_mapping.get(data_config.language)\n",
        "\n",
        "def load_filelist(path) -> list:\n",
        "    file_list = []\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for idx, line in enumerate(f):\n",
        "            audio_path, text = line.strip().split('|', maxsplit=1)\n",
        "            file_list.append((str(idx), audio_path, text))\n",
        "    return file_list\n",
        "\n",
        "@ torch.inference_mode()\n",
        "def process_filelist(line) -> str:\n",
        "    idx, audio_path, text = line\n",
        "    audio = load_and_resample_audio(audio_path, mel_config.sample_rate, device=device) # shape: [1, time]\n",
        "    if audio is not None:\n",
        "        # get output path\n",
        "        audio_name, _ = os.path.splitext(os.path.basename(audio_path))\n",
        "\n",
        "        try:\n",
        "            phone = g2p(text)\n",
        "            if len(phone) > 0:\n",
        "                mel = mel_extractor(audio.to(device)).cpu().squeeze(0) # shape: [n_mels, time // hop_length]\n",
        "                output_mel_path = os.path.join(output_mel_dir, f'{idx}_{audio_name}.pt')\n",
        "                torch.save(mel, output_mel_path)\n",
        "\n",
        "                if data_config.resample:\n",
        "                    audio_path = os.path.join(output_wav_dir, f'{idx}_{audio_name}.wav')\n",
        "                    torchaudio.save(audio_path, audio.cpu(), mel_config.sample_rate)\n",
        "                return json.dumps({'mel_path': output_mel_path, 'phone': phone, 'audio_path': audio_path, 'text': text, 'mel_length': mel.size(-1)}, ensure_ascii=False, allow_nan=False)\n",
        "        except Exception as e:\n",
        "            print(f'Error processing {audio_path}: {str(e)}')\n",
        "\n",
        "\n",
        "def main():\n",
        "    set_start_method('spawn') # CUDA must use spawn method\n",
        "    input_filelist = load_filelist(input_filelist_path)\n",
        "    results = []\n",
        "\n",
        "    with Pool(processes=2) as pool:\n",
        "        for result in tqdm(pool.imap(process_filelist, input_filelist), total=len(input_filelist)):\n",
        "            if result is not None:\n",
        "                results.append(f'{result}\\n')\n",
        "\n",
        "    # save filelist\n",
        "    with open(output_filelist_path, 'w', encoding='utf-8') as f:\n",
        "        f.writelines(results)\n",
        "    print(f\"filelist file has been saved to {output_filelist_path}\")\n",
        "\n",
        "# faster and use much less CPU\n",
        "torch.set_num_threads(1)\n",
        "torch.set_num_interop_threads(1)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HrTEPxu72e87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5rMeBmMd0DP",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Preprocess dataset\n",
        "!python preprocess.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6WgVFGbQhCz"
      },
      "source": [
        "**Modifying config.py**\n",
        "\n",
        "\n",
        "\n",
        "*   num_epochs isnt really needed to be modified for a pretrained session\n",
        "*   test_dataset_path isnt needed, just copy and paste the same path of train_dataset_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Variables that you might want to modify later in the future if needed\n",
        "*   batch_size\n",
        "*   learning_rate (found in the config.py file)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/StableTTS/config.py\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class MelConfig:\n",
        "    sample_rate: int = 44100\n",
        "    n_fft: int = 2048\n",
        "    win_length: int = 2048\n",
        "    hop_length: int = 512\n",
        "    f_min: float = 0.0\n",
        "    f_max: float = None\n",
        "    pad: int = 0\n",
        "    n_mels: int = 128\n",
        "    center: bool = False\n",
        "    pad_mode: str = \"reflect\"\n",
        "    mel_scale: str = \"slaney\"\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.pad == 0:\n",
        "            self.pad = (self.n_fft - self.hop_length) // 2\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    hidden_channels: int = 256\n",
        "    filter_channels: int = 1024\n",
        "    n_heads: int = 4\n",
        "    n_enc_layers: int = 3\n",
        "    n_dec_layers: int = 6\n",
        "    kernel_size: int = 3\n",
        "    p_dropout: int = 0.1\n",
        "    gin_channels: int = 256\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    train_dataset_path: str = '' #@param {type:\"string\"}\n",
        "    test_dataset_path: str = '' #@param {type:\"string\"}\n",
        "    batch_size: int = 32 #@param {type:\"integer\"}\n",
        "    learning_rate: float = 1e-4\n",
        "    num_epochs: int = 10000 #@param {type:\"integer\"}\n",
        "    model_save_path: str = '' #@param {type:\"string\"}\n",
        "    log_dir: str = '' #@param {type:\"string\"}\n",
        "    log_interval: int = 25 #@param {type:\"integer\"}\n",
        "    save_interval: int = 50 #@param {type:\"integer\"}\n",
        "    warmup_steps: int = 200\n",
        "\n",
        "@dataclass\n",
        "class VocosConfig:\n",
        "    input_channels: int = 128\n",
        "    dim: int = 512\n",
        "    intermediate_dim: int = 1536\n",
        "    num_layers: int = 8"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Br6xtCzL3jgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVhhTJssegbf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Start training!\n",
        "log_dir = '' #@param {type:\"string\"}\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {log_dir}\n",
        "!python train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELfM9tM6fyUK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Inference Tab!\n",
        "from IPython.display import Audio, display\n",
        "import torch\n",
        "\n",
        "from api import StableTTSAPI\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "tts_model_path = '' #@param {type:\"string\"}\n",
        "vocoder_model_path = '/content/StableTTS/vocoders/pretrained/firefly-gan-base-generator.ckpt' # path to vocoder checkpoint\n",
        "vocoder_type = 'ffgan' # ffgan or vocos\n",
        "\n",
        "# vocoder_model_path = './vocoders/pretrained/vocos.pt'\n",
        "# vocoder_type = 'vocos'\n",
        "\n",
        "model = StableTTSAPI(tts_model_path, vocoder_model_path, vocoder_type)\n",
        "model.to(device)\n",
        "\n",
        "tts_param, vocoder_param = model.get_params()\n",
        "print(f'tts_param: {tts_param}, vocoder_param: {vocoder_param}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYitjaZ5fz1H",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "text = 'test' #@param {type:\"string\"}\n",
        "ref_audio = 'path'#@param {type:\"string\"}\n",
        "language = 'english' #@param [\"english\", \"japanese\", \"chinese\"]\n",
        "solver = 'dopri5' #@param [\"dopri5\", \"euler\", \"midpoint\"]\n",
        "steps = 30 #@param {type:\"slider\", min:0, max:50, step:1}\n",
        "cfg = 3  #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "audio_output, mel_output = model.inference(text, ref_audio, language, steps, 1, 1, solver, cfg)\n",
        "\n",
        "display(Audio(ref_audio))\n",
        "display(Audio(audio_output, rate=model.mel_config.sample_rate))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMoH0uIg8pvMmhMFUEgbAuq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}